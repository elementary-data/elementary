name: Test warehouse platform
on:
  workflow_dispatch:
    inputs:
      warehouse-type:
        type: choice
        required: true
        description: Type of warehouse platform
        options:
          - snowflake
          - bigquery
          - redshift
          - databricks
          - spark
      elementary-ref:
        type: string
        required: false
        description: Branch or tag to checkout for 'elementary' repository
      dbt-data-reliability-ref:
        type: string
        required: false
        description: Branch or tag to checkout for 'dbt-data-reliability' repository
      dbt-version:
        type: string
        required: false
        description: dbt's version to test with
      should-run-tests:
        type: boolean
        required: false
        default: true
        description: Whether to run E2E tests
      clear-tests:
        type: boolean
        required: false
        default: true
        description: Whether to clean test environment

  workflow_call:
    inputs:
      warehouse-type:
        type: string
        required: true
      should-run-tests:
        type: boolean
        required: false
        default: true
      elementary-ref:
        type: string
        required: false
      dbt-data-reliability-ref:
        type: string
        required: false
      dbt-version:
        type: string
        required: false
      clear-tests:
        type: boolean
        required: false
        default: true

env:
  BRANCH_NAME: ${{ github.head_ref || github.ref_name }}

jobs:
  test:
    runs-on: ubuntu-latest
    concurrency:
      group: tests-${{ inputs.warehouse-type }}-${{ github.head_ref || github.ref_name }}
      cancel-in-progress: true
    steps:
      - name: Write dbt profiles
        env:
          PROFILES_YML: ${{ secrets.CI_PROFILES_YML }}
        run: |
          mkdir -p ~/.dbt
          UNDERSCORED_REF_NAME=$(echo "${{ env.BRANCH_NAME }}" | sed "s/-/_/g")
          echo "$PROFILES_YML" | base64 -d | sed "s/<SCHEMA_NAME>/py_$UNDERSCORED_REF_NAME/g" > ~/.dbt/profiles.yml

      - name: Checkout Elementary
        uses: actions/checkout@v3
        with:
          path: elementary
          ref: ${{ inputs.elementary-ref }}

      - name: Checkout dbt package
        uses: actions/checkout@v3
        with:
          repository: elementary-data/dbt-data-reliability
          path: dbt-data-reliability
          ref: ${{ inputs.dbt-data-reliability-ref }}

      - name: Setup Python
        uses: actions/setup-python@v4
        with:
          python-version: "3.7.5"

      - name: Install Spark requirements
        if: inputs.warehouse-type == 'spark'
        run: sudo apt-get install python-dev libsasl2-dev gcc

      - name: Install Elementary
        run: pip install "./elementary[${{ inputs.warehouse-type }}]"

      - name: Upload build artifact
        uses: actions/upload-artifact@v3
        with:
          name: build
          path: elementary/build

      - name: Install dbt
        if: inputs.dbt-version
        run: |
          pip install dbt-core==${{ inputs.dbt-version }}
          pip install dbt-${{ inputs.warehouse-type }}==${{ inputs.dbt-version }}

      - name: Install dbt package
        run: |
          ELEMENTARY_PKG_LOCATION=$(pip show elementary-data | grep -i location | awk '{print $2}')
          DBT_PROJECT_PATH="$ELEMENTARY_PKG_LOCATION/elementary/monitor/dbt_project"
          DBT_PKGS_PATH="$DBT_PROJECT_PATH/dbt_packages"
          dbt deps --project-dir "$DBT_PROJECT_PATH"
          rm -rf "$DBT_PKGS_PATH/elementary"
          ln -vs "$GITHUB_WORKSPACE/dbt-data-reliability" "$DBT_PKGS_PATH/elementary"

      - name: Run E2E tests
        if: github.event_name != 'workflow_dispatch' || inputs.should-run-tests
        run: |
          dbt deps --project-dir ./dbt-data-reliability/integration_tests
          python ./dbt-data-reliability/integration_tests/run_e2e_tests.py -t "${{ inputs.warehouse-type }}" --clear-tests "${{ inputs.clear-tests }}"

      - name: Run help
        run: edr --help

      - name: Run monitor
        env:
          SLACK_WEBHOOK: ${{ secrets.CI_SLACK_WEBHOOK }}
        run: edr monitor -t "${{ inputs.warehouse-type }}" --slack-webhook "$SLACK_WEBHOOK"

      - name: Run report
        run: edr monitor report -t "${{ inputs.warehouse-type }}" --file-path "report_${{ inputs.warehouse-type }}_${{ env.BRANCH_NAME }}.html"

      - name: Upload report artifact
        uses: actions/upload-artifact@v3
        with:
          name: report_${{ inputs.warehouse-type }}_${{ env.BRANCH_NAME }}.html
          path: report_${{ inputs.warehouse-type }}_${{ env.BRANCH_NAME }}.html

      - name: Write GCS keyfile
        env:
          GCS_KEYFILE: ${{ secrets.GCS_KEYFILE }}
        run: echo "$GCS_KEYFILE" | base64 -d > /tmp/gcs_keyfile.json

      - name: Run send report
        env:
          SLACK_TOKEN: ${{ secrets.CI_SLACK_TOKEN }}
          AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}

        run: >
          edr monitor send-report -t "${{ inputs.warehouse-type }}" --slack-file-name "report_${{ inputs.warehouse-type }}_${{ env.BRANCH_NAME }}.html"
          --slack-token "$SLACK_TOKEN" --slack-channel-name data-ops --bucket-file-path "ci_reports/report_${{ inputs.warehouse-type }}_${{ env.BRANCH_NAME }}.html"
          --aws-access-key-id "$AWS_ACCESS_KEY_ID" --aws-secret-access-key "$AWS_SECRET_ACCESS_KEY" --s3-bucket-name elementary-ci-artifacts
          --google-service-account-path /tmp/gcs_keyfile.json --gcs-bucket-name elementary_ci_artifacts
          --update-bucket-website true

      - name: Upload edr log
        if: ${{ always() }}
        uses: actions/upload-artifact@v3
        with:
          name: edr.log
          path: edr.log
