---
title: "Elementary in production"
---

Running Elementary in production means to include the dbt package in your production dbt project, 
and setting up an automated manner to run the Elementary CLI.

You can choose any system that allows you to orchestrate a CLI execution, as long as it can meet the following requirements:
- Full installation of Elementary Python package and dependencies. 
- Network access to the data warehouse.
- Access to a `profiles.yml` file with `elementary` profile name.
- Read and write permissions to the Elementary schema.  

## Elementary production deployment and jobs 

Your deployment of Elementary has two parts:

**Part 1 - Elementary package in your production dbt project**

In your dbt jobs, after you deploy the Elementary dbt package: 
1. **Run and test tesults** - Collected by default as part of your runs.
2. **Elementary tests** - Make sure your dbt test runs include elementary tests. 
3. **Update dbt artifacts** - Elementary uses the dbt artifacts models to enrich the report, alerts and lineage. To update the artifacts data, run the elementary dbt artifacts models. 


**Part 2 - Elementary CLI**

On an orchestration system of your choice, run the CLI to:
1. **Send Slack alerts** - Use the `edr monitor` command and Slack integration.
2. **Generate a report** - Use the `edr monitor report` or `edr monitor send-report` that has built in support for sending the report to Slack / GCS / S3.

## When to run Elementary?

For sending alerts or generating a report, there are two options:

1. **Run Elementary CLI after each relevant dbt job** (`dbt test` / `dbt build` / `dbt run`).
2. **Run Elementary CLI periodically** in a frequency that fits your dbt job executions.

Here's why.

We store _artifacts_, which is information about dbt-related resources such as models, tests, etc.
You can view as models called `dbt_models`, `dbt_tests`, `dbt_exposures`, and so on.

We internally use those models in order to gather the latest information on your dbt resources.
For instance, you could define an `owner` or `subscribers` on your models, and we'll use them to tag the relevant users in our alerts.

For our alerts to work properly, we'd want to make sure that the artifact models have been built according to the latest environment. This is why we recommend to run our models after changes in your project.

We're working on changing the design so that you won't need to run those models, and instead we'll upload it for you using the `on-run-end` hook.
This method makes sure that Elementary will be kept in sync with the latest resources.

Hope that clarifies it.

To make sure your project data is updated, we recommend running the elementary dbt artifacts models **on each PR merge** to your dbt production project:  
```shell
dbt run --select edr.dbt_artifacts
```

## Ways to run Elementary in production

If your organization is using dbt-core, it would probably be a good choice to orchestrate Elementary using the same system that orchestrates dbt.

Any automation server / orchestration tool supports running a CLI tool like Elementary.

Some options include: 

1. GitHub Actions - Checkout the [Elementary GitHub Action workflow](https://github.com/elementary-data/run-elementary-action) we created.
2. Airflow
3. Prefect
5. Using cron

## Need help?

If you want to consult on production deployment, we would love to help!  
Please reach out to us on [Slack](https://join.slack.com/t/elementary-community/shared_invite/zt-uehfrq2f-zXeVTtXrjYRbdE_V6xq4Rg), we could talk there or schedule a deployment video call. 

