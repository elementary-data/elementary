You will connect Elementary Cloud to Bigquery for syncing the Elementary schema (created by the [Elementary dbt package](/cloud/onboarding/quickstart-dbt-package)).

<Snippet file="dwh/bigquery/cloud_service_account.mdx" />

<Snippet file="cloud/integrations/permissions-and-security.mdx" />

### Fill the connection form

Provide the following fields:

- **Service account file**: The service account file you generated for Elementary. For more information, refer to [Create BigQuery service account](/integrations/bigquery#create-bigquery-service-account).
- **Project**: The name of your BigQuery project.
- **Elementary dataset**: The name of your Elementary dataset. Usually `[dataset name]_elementary`.
- **Location**: Use this field to configure the location of BigQuery datasets as per [the BigQuery documentation](https://cloud.google.com/bigquery/docs/locations).

### Uploading columns data

In order to let Elementary Cloud access metadata about the columns in your data warehouse, you need to run the following command:

```
dbt run-operation elementary.upload_dbt_columns
```

You may choose to run this command in one of the following ways:

1. Manually whenever there is a schema change in your dataset - Not recommended.
2. As part of your `dbt` pipeline - Recommended if you have one main pipeline.
3. As an independent pipeline - Recommended if you have a lot of small pipelines running in different times.

<Snippet file="cloud/integrations/ip-allowlist.mdx" />
