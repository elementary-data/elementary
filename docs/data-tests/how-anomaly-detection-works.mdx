---
title: "Elementary anomaly detection tests"
sidebarTitle: "Elementary anomaly detection"
---

Elementary data anomaly detection tests monitor a specific metric (like row count, null rate, average value, etc.) and compare recent values to historical values.
This is done to detect [significant changes and deviations](/data-tests/data-anomaly-detection), that are probably data reliability issues.

## What happens on each test?

Upon running a test, your data is split into time buckets based on the [`time_bucket`](/data-tests/anomaly-detection-configuration/time-bucket) field and is limited by
the [`days_back`](/data-tests/anomaly-detection-configuration/days-back) var. The test then compares a certain metric (e.g. row count) of the buckets that are within the detection
period ([`backfill_days`](/data-tests/anomaly-detection-configuration/backfill-days)) to the row count of all the previous time buckets within the [`days_back`](/data-tests/anomaly-detection-configuration/days-back) period.
If there were any anomalies in the detection period, the test will fail.
On each test elementary package executes the relevant monitors, and searches for anomalies by comparing to historical metrics.

<Tooltip tip="Anomaly detection tests core concepts">
  <img
    src="https://raw.githubusercontent.com/elementary-data/assets-hosting/master/anomaly_detection/elementary-anomaly-detection-core-concepts.png"
    alt="Elementary anomaly detection tests core concepts"
  />
</Tooltip>

To learn more, refer to [core concepts](/data-tests/how-anomaly-detection-works).

## What does it mean when a test fails?

When a test fail, it means that an anomaly was detected on this metric and dataset. To learn more, refer to [anomaly detection method](/data-tests/data-anomaly-detection).

## Core concepts

### Anomaly

A value in the detection set that is an outlier comparing to the expected range calculated based on the training set.

### Monitored data set

The data set we run the data monitor against, and includes the training set values and detection set values.

### Data monitors

When we use anomaly detection tests we can monitor different metrics to detect problems - freshness, volume, nullness, uniqueness, distribution, etc.
Each different metric we collect is a ‘data monitor’.

### Training set

The set of values used as a reference point to calculate the expected range.

### Detection set

The set of values that are compared to the expected range.
If a value in the detection set is an outlier to the expected range, it will be flagged as an anomaly.

### Expected range

Based of the values in the training test, we calculate an expected range for the monitor.
Each data point in the detection period will be compared to the expected range calculated based on it’s training set.

### Training period

The period of time for which the training set is collected.
As data changed over time, we don’t consider the entire history of the metric, just a recent period.

### Detection period

The values in the detection period will be compared to the expected range calculated using the training set.
If a data point is outside the expected range and is part of the detection period, it is flagged as an anomaly.

### Time bucket

To calculate how data changes over time and detect issues, we split the data into consistent time buckets.
For example, if we use daily time bucket and monitor for row count anomalies, we will count new rows per day.

### Detection algorithm

Read about it in [data anomaly detection method](/data-tests/data-anomaly-detection).

## Tests configuration and core concepts

Not all data sets are the same, so Elementary offers configuration options for the anomaly detection tests.  
To detect data issues with high accuracy, it is important to leverage the configuration options.

Configuration params related directly to the test's core concepts:

**Data monitors**

- [column_anomalies](/data-tests/anomaly-detection-configuration/column-anomalies)

**Expected range**

- [anomaly_sensitivity](/data-tests/anomaly-detection-configuration/anomaly-sensitivity)
- [anomaly_direction](/data-tests/anomaly-detection-configuration/anomaly-direction)

**Detection period and detection set**

- [backfill_days](/data-tests/anomaly-detection-configuration/backfill-days)

**Training period and training set**

- [days_back](/data-tests/anomaly-detection-configuration/days-back)
- [seasonality](/data-tests/anomaly-detection-configuration/seasonality)

**Time buckets**

- [timestamp_column](/data-tests/anomaly-detection-configuration/timestamp-column)
- [time_bucket](/data-tests/anomaly-detection-configuration/time-bucket)

**Monitored data set**

- [where_expression](/data-tests/anomaly-detection-configuration/where-expression)
- [dimensions](/data-tests/anomaly-detection-configuration/dimensions)
