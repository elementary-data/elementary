---
title: "Add anomaly detection tests"
---

After you [install the dbt package](/quickstart#install-the-dbt-package), you can add Elementary data anomaly detection
tests.

## Data anomaly detection dbt tests

Elementary dbt package includes **anomaly detection tests, implemented as [dbt tests](https://docs.getdbt.com/docs/building-a-dbt-project/tests)**.
These tests can detect anomalies in volume, freshness, null rates, and anomalies in specific dimensions, among others. 
The tests are configured and executed like any other tests in your project.

<Tooltip tip="Anomaly detection test result example from Elementary report">
<img
src="/pics/anomalies/anomaly-example.png"
alt="Demo"
/>
</Tooltip>

## Available anomaly detection tests

### Table (model / source) tests

<Accordion title="elementary.volume_anomalies">

Monitors the row count of your table over time per time bucket (if configured without `timestamp_column`, will count table total rows).

Upon running the test, your data is split into time buckets (daily by default, configurable with the `time bucket`
field), and then we compute the row count per bucket for the last `days_back` days (by default 14).

The test then compares the row count of buckets within the detection period (last 2 days by default, controlled by the
`backfill_days` var), and compares it with the row count of the previous time buckets.
If there were any anomalies during the detection period, the test will fail.

For advanced configuration of Elementary anomaly tests, please click [here](/guides/add-elementary-tests#advanced-configuration-for-your-elementary-tests)


<CodeGroup>

```yml Models
version: 2

models:
  - name: < model name >
    tests:
      - elementary.volume_anomalies:
          timestamp_column: < timestamp column >
          where_expression: < sql expression >
          time_bucket:                # Daily by default
            period: < time period >
            count: < number of periods >
```

```yml Models example
version: 2

models:
  - name: login_events
    config:
      elementary:
        timestamp_column: 'loaded_at'
    tests:
      - elementary.volume_anomalies:
          where_expression: "event_type in ('event_1', 'event_2') and country_name != 'unwanted country'"
          time_bucket:
            period: day
            count: 1
          # optional - use tags to run elementary tests on a dedicated run
          tags: ['elementary']
          config:
          # optional - change severity
            severity: warn

  - name: users
    # if no timestamp is configured, elementary will monitor without time filtering
    tests:
      - elementary.volume_anomalies:
          tags: ['elementary']
```

</CodeGroup>

</Accordion>

<Accordion title="elementary.freshness_anomalies">

`elementary.freshness_anomalies`

Monitors the freshness of your table over time, as the expected time between data updates.

Upon running the test, your data is split into time buckets (daily by default, configurable with the `time bucket`
field), and then we compute the maximum freshness value per bucket for the last `days_back` days (by default 14).

The test then compares the freshness of buckets within the detection period (last 2 days by default, controlled by the
`backfill_days` var), and compares it with the freshness of the previous time buckets.
If there were any anomalies during the detection period, the test will fail.

For advanced configuration of Elementary anomaly tests, please click [here](/guides/add-elementary-tests#advanced-configuration-for-your-elementary-tests)

<CodeGroup>

```yml Models
version: 2

models:
  - name: < model name >
    tests:
      - elementary.freshness_anomalies:
          timestamp_column: < timestamp column >            # Mandatory
          where_expression: < sql expression >
          time_bucket:              # Daily by default
            period: < time period >
            count: < number of periods >
```

```yml Models example
version: 2

models:
  - name: login_events
    tests:
      - elementary.freshness_anomalies:
          timestamp_column: 'updated_at'
          # optional - use tags to run elementary tests on a dedicated run
          tags: ['elementary']
          config:
          # optional - change severity
            severity: warn
```

</CodeGroup>

</Accordion>

<Accordion title="elementary.event_freshness_anomalies">

`elementary.event_freshness_anomalies`

Monitors the freshness of event data over time, as the expected time it takes each event to load -
that is, the time between the when the event actually occurs (the event timestamp), and when it is loaded to the
database (the update timestamp).

This test compliments the `freshness_anomalies` test and is primarily intended for data that is updated in a
continuous / streaming fashion.

The test can work in a couple of modes:
- If only an `event_timestamp_column` is supplied, the test measures over time the difference between the current
timestamp ("now") and the most recent event timestamp.
- If both an `event_timestamp_column` and an `update_timestamp_column` are provided, the test will measure over time
the difference between these two columns.

For advanced configuration of Elementary anomaly tests, please click [here](/guides/add-elementary-tests#advanced-configuration-for-your-elementary-tests)

<CodeGroup>

```yml Models
version: 2

models:
  - name: < model name >
    tests:
      - elementary.event_freshness_anomalies:
          event_timestamp_column: < timestamp column >          # Mandatory
          update_timestamp_column: < timestamp column >         # Optional
          where_expression: < sql expression >
          time_bucket:              # Daily by default
            period: < time period >
            count: < number of periods >
```

```yml Models example
version: 2

models:
  - name: login_events
    tests:
      - elementary.event_freshness_anomalies:
          event_timestamp_column: 'occurred_at'
          update_timestamp_column: 'updated_at'
          # optional - use tags to run elementary tests on a dedicated run
          tags: ['elementary']
          config:
          # optional - change severity
            severity: warn
```

</CodeGroup>

</Accordion>

<Accordion title="elementary.dimension_anomalies">

`elementary.dimension_anomalies`

This test monitors the frequency of values in the configured dimension over time, and alerts on unexpected changes in
the distribution.
It is best to configure it on low-cardinality fields.
The test counts rows grouped by given columns/expressions, and can be configured using the `dimensions`
and `where_expression` keys.

For advanced configuration of Elementary anomaly tests, please click [here](/guides/add-elementary-tests#advanced-configuration-for-your-elementary-tests)

<CodeGroup>

```yml Models
version: 2

models:
  - name: < model name >
    config:
      elementary:
        timestamp_column: < timestamp column >
    tests:
      - elementary.dimension_anomalies:
          dimensions: < columns or sql expressions of columns >
          # optional - configure a where a expression to accurate the dimension monitoring
          where_expression: < sql expression >
          time_bucket:              # Daily by default
            period: < time period >
            count: < number of periods >
```

```yml Models example
version: 2

models:
  - name: login_events
    config:
      elementary:
        timestamp_column: "loaded_at"
    tests:
      - elementary.dimension_anomalies:
          dimensions:
            - event_type
            - country_name
          where_expression: "event_type in ('event_1', 'event_2') and country_name != 'unwanted country'"
          time_bucket:
            period: hour
            count: 4
          # optional - use tags to run elementary tests on a dedicated run
          tags: ["elementary"]
          config:
            # optional - change severity
            severity: warn

  - name: users
    # if no timestamp is configured, elementary will monitor without time filtering
    tests:
      - elementary.dimension_anomalies:
          dimensions:
            - event_type
          tags: ["elementary"]
```

</CodeGroup>

</Accordion>

<Accordion title="elementary.all_columns_anomalies">

`elementary.all_columns_anomalies`

Executes column level monitors and anomaly detection on all the columns of the table. Specific monitors
are [detailed here](/guides/data-anomaly-detection#tests-and-monitors-types) and can be configured using
the `all_columns_anomalies` key.

For advanced configuration of Elementary anomaly tests, please click [here](/guides/add-elementary-tests#advanced-configuration-for-your-elementary-tests)

<CodeGroup>

```yml Models
version: 2

models:
  - name: < model name >
    config:
      elementary:
        timestamp_column: < timestamp column >
    tests:
      - elementary.all_columns_anomalies:
          column_anomalies: < specific monitors, all if null >
          where_expression: < sql expression >
          time_bucket:              # Daily by default
            period: < time period >
            count: < number of periods >
```

```yml Models example
version: 2

models:
  - name: login_events
    config:
      elementary:
        timestamp_column: "loaded_at"
    tests:
      - elementary.all_columns_anomalies:
          where_expression: "event_type in ('event_1', 'event_2') and country_name != 'unwanted country'"
          time_bucket:
            period: day
            count: 1
          tags: ["elementary"]
          # optional - change global sensitivity
          sensitivity: 3.5
```

</CodeGroup>

#### Column anomalies

<Snippet file="column-metrics.mdx" />

</Accordion>

### Column tests

<Accordion title="elementary.column_anomalies">

`elementary.column_anomalies`

Executes column level monitors and anomaly detection. Specific monitors
are [detailed here](/guides/data-anomaly-detection#tests-and-monitors-types) and can be configured using
the `column_anomalies` key.

For advanced configuration of Elementary anomaly tests, please click [here](/guides/add-elementary-tests#advanced-configuration-for-your-elementary-tests)

<CodeGroup>

```yml Models
version: 2

models:
  - name: < model name >
    config:
      elementary:
        timestamp_column: < timestamp column >
    columns:
      - name: < column name >
        tests:
          - elementary.column_anomalies:
              column_anomalies: < specific monitors, all if null >
              where_expression: < sql expression >
              time_bucket:              # Daily by default
                              period: < time period >
                              count: < number of periods >

  - name: < model name >
    ## if no timestamp is configured, elementary will monitor without time filtering
    columns:
      - name: < column name >
        tests:
          - elementary.column_anomalies:
              column_anomalies: < specific monitors, all if null >
              where_expression: < sql expression >
```

```yml Models example
version: 2

models:
  - name: login_events
    config:
      elementary:
        timestamp_column: 'loaded_at'
    columns:
      - name: user_name
        tests:
          - elementary.column_anomalies:
              column_anomalies:
                - missing_count
                - min_length
              where_expression: "event_type in ('event_1', 'event_2') and country_name != 'unwanted country'"
              time_bucket:
                period: day
                count: 1
              tags: ['elementary']

  - name: users
    ## if no timestamp is configured, elementary will monitor without time filtering
    tests:
        elementary.table_anomalies
          tags: ['elementary']
    columns:
      - name: user_id
        tests:
          - elementary.column_anomalies:
              tags: ['elementary']
              timestamp_column: 'updated_at'
              where_expression: "event_type in ('event_1', 'event_2') and country_name != 'unwanted country'"
              time_bucket:
                period: < time period >
                count: < number of periods >
      - name: user_name
        tests:
          - elementary.column_anomalies:
              column_anomalies:
                - missing_count
                - min_length
              tags: ['elementary']
```

</CodeGroup>

#### Column anomalies

<Snippet file="column-metrics.mdx" />

</Accordion>


#### Adding tests examples: 

<CodeGroup>

```yml Models
version: 2

models:
  - name: < model name >
    config:
      elementary:
        timestamp_column: < timestamp column >
    tests:
      - elementary.table_anomalies:
          table_anomalies: < specific monitors, all if null >
          # optional - configure different freshness column than timestamp column
          freshness_column: < freshness_column >
          where_expression: < sql expression >
          time_bucket:
            period: < time period >
            count: < number of periods >
      - elementary.all_columns_anomalies:
          column_anomalies: < specific monitors, all if null >
          where_expression: < sql expression >
          time_bucket:
            period: < time period >
            count: < number of periods >
      - elementary.schema_changes
      - elementary.dimension_anomalies:
          dimensions: < columns or sql expressions of columns >
          # optional - configure a where a expression to accurate the dimension monitoring
          where_expression: < sql expression >
          time_bucket:
            period: < time period >
            count: < number of periods >

  - name: < model name >
    ## if no timestamp is configured, elementary will monitor without time filtering
    columns:
      - name: < column name >
        tests:
          - elementary.column_anomalies:
              column_anomalies: < specific monitors, all if null >
```

```yml Models example
version: 2

models:
  - name: login_events
    config:
      elementary:
        timestamp_column: 'loaded_at'
    tests:
        - elementary.table_anomalies:
            table_anomalies:
              - row_count
              - freshness
            # optional - use tags to run elementary tests on a dedicated run
            tags: ['elementary']
            config:
            # optional - change severity
              severity: warn
        - elementary.all_columns_anomalies:
            tags: ['elementary']
            # optional - change global sensitivity
            sensitivity: 3.5
            timestamp_column: 'updated_at'
        - elementary.schema_changes:
            tags: ['elementary']
            config:
              severity: warn
        - elementary.dimension_anomalies:
            dimensions:
              - event_type
              - country_name
            where_expression: "event_type in ('event_1', 'event_2') and country_name != 'unwanted country'"
            # optional - use tags to run elementary tests on a dedicated run
            tags: ['elementary']
            config:
            # optional - change severity
              severity: warn

  - name: users
    ## if no timestamp is configured, elementary will monitor without time filtering
    tests:
        elementary.table_anomalies
          tags: ['elementary']
    columns:
      - name: user_id
        tests:
          - elementary.column_anomalies:
              tags: ['elementary']
              timestamp_column: 'updated_at'
      - name: user_name
        tests:
          - elementary.column_anomalies:
              column_anomalies:
                - missing_count
                - min_length
              tags: ['elementary']
```

```yml Sources
sources:
  - name: < some name >
    database: < datatbase >
    schema: < schema >
    tables:
      - name: < table_name >
        ## sources don't have config, so elementary config is placed under 'meta'
        meta:
          elementary:
            timestamp_column: < source timestamp column >
        tests: <here you will add elementary monitors as tests>
```

```yml Sources example
sources:
  - name: 'my_non_dbt_data'
    database: 'raw_events'
    schema: 'product'
    tables:
      - name: 'raw_product_login_events'
      ## sources don't have config, so elementary config is placed under 'meta'
        meta:
          elementary:
            timestamp_column: 'loaded_at'
        tests:
          - elementary.table_anomalies
          - elementary.dimension_anomalies:
              dimensions:
                - event_type
          - elementary.all_columns_anomalies:
              column_anomalies:
                - null_count
                - missing_count
                - zero_count
          - elementary.schema_changes_from_baseline
        columns:
          - name: user_id
            data_type: text
            tests:
              - elementary.column_anomalies
          - name: event_name
            data_type: text
          - name: event_id
            data_type: integer
```

</CodeGroup>

## Configure your elementary anomaly detection tests

The elementary anomaly detection tests described above can work out-of-the-box with default configuration. However,
we support additional configuration that can be used to customize their behavior, depending on your needs.
Read all about data anomaly detection tests configuration [here](/guides/elementary-tests-configuration).

We recommend adding a tag to the tests so you could execute these in a dedicated run using the selection
parameter `--select tag:elementary`.
If you wish to only be warned on anomalies, configure the severity of the tests to warn.


## What happens on each test?

Upon running a test, your data is split into time buckets based on the `time_bucket` field and is limited by
the `days_back` var. The test then compares a certain metric (e.g. row count) of the buckets that are within the detection
period (`backfill_days`) to the row count of all the previous time buckets within the `days_back` period.
If there were any anomalies in the detection period, the test will fail.
On each test elementary package executes the relevant monitors, and searches for anomalies by comparing to historical
metrics.
At the end of the `dbt test` run, all results and collected metrics are merged into the elementary models.

## What does it mean when a test fails?

When a test fail, it means that an anomaly was detected on this metric and dataset. To learn more, refer
to [anomaly detection](/guides/data-anomaly-detection#anomaly-detection).


